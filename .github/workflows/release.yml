name: Release
on:
  push:
    tags:
      - "202*" # any tag. GH releases (containing binaries for download) require tags

jobs:

  prepare:
    runs-on: [ self-hosted, Linux ]
    if: ${{ github.repository_owner == 'rpardini' }}
    outputs:
      tagName: ${{ steps.tagName.outputs.tag }}
    steps:
      - uses: olegtarasov/get-tag@v2.1 # get the tag name from the ref.
        id: tagName
      # This creates an empty release on the tag with just the header.
      - name: Release ${{ matrix.board }}
        uses: softprops/action-gh-release@v1
        if: startsWith(github.ref, 'refs/tags/') # only for tags. GitHub requires tags for releases.
        with:
          body: |
            ### Release ${{ steps.tagName.outputs.tag }}

  "A": # short name because GH will expand with the matrix values
    needs: [ prepare ]
    runs-on: [ self-hosted, Linux, hirsute, '${{ matrix.runnerLabel }}', '${{ matrix.runnerLabelKernel }}' ]
    timeout-minutes: 480 # First builds on new machines can take extremely long until caches are primed
    if: ${{ github.repository_owner == 'rpardini' }}
    strategy:
      fail-fast: false # let other jobs try to complete if one fails
      matrix:
        # include syntax allows sparse matrices
        # see # https://docs.github.com/en/actions/reference/workflow-syntax-for-github-actions#example-including-new-combinations

        # board: will build rpardini-<board>.conf in userpatches.
        # desc: markdown for description in release notes
        # runnerLabel: goes into runs-on to select preferred builder via label
        # vars: env vars to pass both to scripts and ./compile.sh
        # aa: GH Actions orders the jobs by the first key value. 'aa' should be first. it never is. it is actually quite pointless trying. it's effectively random.

        include:
          - aa: 0010
            board: jethubj80
            desc: JetHub J80, CLI, standard
            runnerLabel: can-build-arm64
            runnerLabelKernel: can-build-kernels
            vars: "CLOUD_IMAGE=no"
          - aa: 0020
            board: jethubj100
            desc: JetHub J100, CLI, standard
            runnerLabel: can-build-arm64
            runnerLabelKernel: can-build-kernels
            vars: "CLOUD_IMAGE=no"

#          # regular CLI builds, build first
#          - aa: 0010
#            board: odroidhc4
#            desc: ODROID HC4, CLI, standard
#            runnerLabel: can-build-arm64
#            runnerLabelKernel: can-build-kernels
#            vars: "CLOUD_IMAGE=no"
#          - aa: 0020
#            board: odroidn2
#            desc: ODROID N2+, CLI, standard
#            runnerLabel: can-build-arm64
#            runnerLabelKernel: can-build-kernels
#            vars: "CLOUD_IMAGE=no"
#
#          - aa: 0021
#            board: radxa-zero
#            desc: Radxa Zero, CLI, standard
#            runnerLabel: can-build-arm64
#            runnerLabelKernel: can-build-kernels
#            vars: "CLOUD_IMAGE=no"
#
#          - aa: 0030
#            board: khadas-vim3
#            desc: Khadas VIM3, regular CLI
#            runnerLabel: can-build-arm64
#            runnerLabelKernel: can-build-kernels
#            vars: "CLOUD_IMAGE=no"
#
#          - aa: 0031
#            board: khadas-vim1
#            desc: Khadas VIM1, regular CLI
#            runnerLabel: can-build-arm64
#            runnerLabelKernel: can-build-kernels
#            vars: "CLOUD_IMAGE=no"
#
#          - aa: 0032
#            board: khadas-vim2
#            desc: Khadas VIM2, regular CLI
#            runnerLabel: can-build-arm64
#            runnerLabelKernel: can-build-kernels
#            vars: "CLOUD_IMAGE=no"
#
#          - aa: 0033
#            board: khadas-vim3l
#            desc: Khadas VIM3L, regular CLI
#            runnerLabel: can-build-arm64
#            runnerLabelKernel: can-build-kernels
#            vars: "CLOUD_IMAGE=no"
#
#          - aa: 0034
#            board: lafrite
#            desc: lafrite, regular CLI
#            runnerLabel: can-build-arm64
#            runnerLabelKernel: can-build-kernels
#            vars: "CLOUD_IMAGE=no"
#
#          - aa: 0035
#            board: lepotato
#            desc: lepotato, regular CLI
#            runnerLabel: can-build-arm64
#            runnerLabelKernel: can-build-kernels
#            vars: "CLOUD_IMAGE=no"
#
#          - aa: 0036
#            board: odroidc2
#            desc: ODROID C2, regular CLI
#            runnerLabel: can-build-arm64
#            runnerLabelKernel: can-build-kernels
#            vars: "CLOUD_IMAGE=no"
#
#          - aa: 0037
#            board: odroidc4
#            desc: ODROID C4, regular CLI
#            runnerLabel: can-build-arm64
#            runnerLabelKernel: can-build-kernels
#            vars: "CLOUD_IMAGE=no"
#
#          - aa: 0038
#            board: nanopik2-s905
#            desc: nanopik2-s905, regular CLI
#            runnerLabel: can-build-arm64
#            runnerLabelKernel: can-build-kernels
#            vars: "CLOUD_IMAGE=no"
#
#          #- aa: 0039
#          #  board: t95z # @TODO: this is not even close to building. my t95z is in production, so no testing
#          #  desc: t95z tvbox (old/deprecated/untested), regular CLI
#          #  runnerLabel: can-build-arm64
#          #  runnerLabelKernel: can-build-kernels
#          #  vars: "CLOUD_IMAGE=no"
#
#          - aa: 0040
#            board: oneplus5
#            desc: OnePlus 5, fastboot-compatible, regular CLI
#            runnerLabel: can-build-arm64
#            runnerLabelKernel: can-build-small-kernels
#            vars: "CLOUD_IMAGE=no"
#          - aa: 0050
#            board: rpi4b
#            desc: Raspberry Pi 4B, using Ubuntu's raspi kernel, regular CLI
#            runnerLabel: can-build-arm64
#            runnerLabelKernel: can-build-rootfs-only
#            vars: "CLOUD_IMAGE=no"
#            aaaa: 8
#
#          # cloud images build after regular cli
#          - aa: 0110
#            board: odroidhc4
#            desc: ODROID HC4, cloud image, user-data at /boot (ext4)
#            runnerLabel: can-build-arm64
#            runnerLabelKernel: can-build-kernels
#            vars: "CLOUD_IMAGE=yes"
#          - aa: 0120
#            board: odroidn2
#            desc: ODROID N2+, cloud image, user-data at /boot (ext4)
#            runnerLabel: can-build-arm64
#            runnerLabelKernel: can-build-kernels
#            vars: "CLOUD_IMAGE=yes"
#          - aa: 0130
#            board: khadas-vim3
#            desc: Khadas VIM3, cloud image, user-data at /boot (ext4)
#            runnerLabel: can-build-arm64
#            runnerLabelKernel: can-build-kernels
#            vars: "CLOUD_IMAGE=yes"
#          - aa: 0140
#            board: oneplus5
#            desc: OnePlus 5, fastboot-compatible, cloud image, user-data at /boot
#            runnerLabel: can-build-arm64
#            runnerLabelKernel: can-build-small-kernels
#            vars: "CLOUD_IMAGE=yes"
#          - aa: 0150
#            board: rpi4b
#            desc: Raspberry Pi 4B, using Ubuntu's raspi kernel, cloud image, user-data at /boot/firmware (FAT)
#            runnerLabel: can-build-arm64
#            runnerLabelKernel: can-build-rootfs-only
#            vars: "CLOUD_IMAGE=yes"
#
#          # then the rest.
#          - aa: 0710
#            board: dkbarm64
#            desc: ARM64 Direct Kernel Boot, -generic kernel, cloud image, for use with kexec/QEMU, user-data from Kernel cmdline only
#            runnerLabel: can-build-arm64
#            runnerLabelKernel: can-build-rootfs-only
#            vars: "CLOUD_IMAGE=yes"
#          - aa: 0720
#            board: uefiarm64
#            desc: UEFI Generic ARM64, with -generic Ubuntu kernel, cloud image, user-data at /boot/efi (FAT)
#            runnerLabel: can-build-arm64
#            runnerLabelKernel: can-build-rootfs-only
#            vars: "CLOUD_IMAGE=yes"
#          - aa: 0730
#            board: uefiarm64
#            desc: UEFI Generic ARM64, with -generic Ubuntu kernel, regular CLI
#            runnerLabel: can-build-arm64
#            runnerLabelKernel: can-build-rootfs-only
#            vars: "CLOUD_IMAGE=no"
#          - aa: 0740
#            board: uefiarm64meta
#            desc: UEFI Generic ARM64 cloud image for metadata-capable clouds (AWS/GCP/OCI/OpenStack/etc)
#            runnerLabel: can-build-arm64
#            runnerLabelKernel: can-build-rootfs-only
#            vars: "CLOUD_IMAGE=yes"
#          - aa: 0750
#            board: uefiarm64-dual-root
#            desc: UEFI Generic ARM64 Dual Root/Rescue e2img, with -generic Ubuntu kernel, cloud image, user-data at /boot for each root
#            runnerLabel: can-build-arm64
#            runnerLabelKernel: can-build-rootfs-only
#            vars: "CLOUD_IMAGE=yes DUAL_ROOT_OUTPUT_E2IMG_ONLY=yes"
#            buildFirst: uefiarm64-rescue-rootfs # rescue is the second root, which contains a rootfs of the first.
#
#          - aa: 0810
#            board: x86dkb
#            desc: x86 Direct Kernel Boot, -generic kernel, cloud image, for use with kexec/QEMU, user-data from Kernel cmdline only
#            runnerLabel: can-build-x86
#            runnerLabelKernel: can-build-rootfs-only
#            vars: "CLOUD_IMAGE=yes"
#          - aa: 0820
#            board: x86uefi
#            desc: UEFI Generic x86, with -generic Ubuntu kernel, cloud image, user-data at /boot/efi (FAT)
#            runnerLabel: can-build-x86
#            runnerLabelKernel: can-build-rootfs-only
#            vars: "CLOUD_IMAGE=yes"
#          - aa: 0830
#            board: x86uefi
#            desc: UEFI Generic x86, with -generic Ubuntu kernel, regular CLI
#            runnerLabel: can-build-x86
#            runnerLabelKernel: can-build-rootfs-only
#            vars: "CLOUD_IMAGE=no"
#          - aa: 0840
#            board: x86uefimeta
#            desc: UEFI Generic x86 cloud image for metadata-capable clouds (AWS/GCP/OCI/OpenStack/etc)
#            runnerLabel: can-build-x86
#            runnerLabelKernel: can-build-rootfs-only
#            vars: "CLOUD_IMAGE=yes"
#          - aa: 0850
#            board: x86uefi-dual-root
#            desc: UEFI Generic x86 Dual Root/Rescue e2img, with -generic Ubuntu kernel, cloud image, user-data at /boot for each root
#            runnerLabel: can-build-x86
#            runnerLabelKernel: can-build-rootfs-only
#            vars: "CLOUD_IMAGE=yes DUAL_ROOT_OUTPUT_E2IMG_ONLY=yes"
#            buildFirst: x86uefi-rescue-rootfs # rescue is the second root, which contains a rootfs of the first.


    steps:

      - name: Checkout this (release) repo into release dir
        uses: actions/checkout@v2
        with:
          path: release

      - name: Preserve previous run caches and cleanup
        run: |
          sudo --preserve-env \
            REGULAR_USER="$(whoami)" \
            RELEASE_OWNER="${{ github.repository_owner }}" \
            RELEASE_OWNER_AND_REPO="${{ github.repository }}" \
            RELEASE_TAG="${{needs.prepare.outputs.tagName}}" \
            bash --noprofile --norc -e release/cleanup.sh

      - name: Checkout build repo
        uses: actions/checkout@v2
        with:
          repository: ${{ github.repository_owner }}/armbian-build
          ref: rpardini-fragments # branch to build from.
          clean: true # true is default. it *will* delete the hosts /dev if mounted inside.
          path: build

      - name: Restore caches
        run: |
          sudo --preserve-env \
            REGULAR_USER="$(whoami)" \
            RELEASE_OWNER="${{ github.repository_owner }}" \
            RELEASE_OWNER_AND_REPO="${{ github.repository }}" \
            RELEASE_TAG="${{needs.prepare.outputs.tagName}}" \
            bash --noprofile --norc -e release/restore_cache.sh

      - name: Build dependency ${{ matrix.buildFirst }} first
        id: buildFirst
        if: ${{ matrix.buildFirst != '' }}
        working-directory: build
        continue-on-error: true
        run: |
          sudo --preserve-env ${{ matrix.vars }} \
            REGULAR_USER="$(whoami)" \
            RELEASE_OWNER="${{ github.repository_owner }}" \
            RELEASE_OWNER_AND_REPO="${{ github.repository }}" \
            RELEASE_TAG="${{needs.prepare.outputs.tagName}}" \
            bash --noprofile --norc -e ../release/build.sh \
            "${{ matrix.buildFirst }}" "${{ matrix.vars }}"

      - name: Build board ${{ matrix.board }}
        id: buildBoard
        working-directory: build
        continue-on-error: true
        run: |
          sudo --preserve-env ${{ matrix.vars }} \
            REGULAR_USER="$(whoami)" \
            RELEASE_OWNER="${{ github.repository_owner }}" \
            RELEASE_OWNER_AND_REPO="${{ github.repository }}" \
            RELEASE_TAG="${{needs.prepare.outputs.tagName}}" \
            bash --noprofile --norc -e ../release/build.sh \
            "${{ matrix.board }}" "${{ matrix.vars }}"

      - name: Compress/Prepare release ${{ matrix.board }}
        id: compress
        working-directory: build/output
        continue-on-error: true
        run: |
          sudo --preserve-env ${{ matrix.vars }} \
            MATRIX_DESC="${{ matrix.desc }}" \
            REGULAR_USER="$(whoami)" \
            RELEASE_OWNER="${{ github.repository_owner }}" \
            RELEASE_OWNER_AND_REPO="${{ github.repository }}" \
            RELEASE_TAG="${{needs.prepare.outputs.tagName}}" \
            bash --noprofile --norc -e ../../release/prepare_release.sh \
            "${{ matrix.board }}" "${{ matrix.vars }}"

      - name: Release ${{ matrix.board }}
        id: release
        uses: softprops/action-gh-release@2d72d869af3bf23602f9593a1e3fd739b80ac1eb # which is v0.1.12, concat release bodies. # @v1 is a moving target
        if: startsWith(github.ref, 'refs/tags/') # only for tags. GitHub requires tags for releases.
        with:
          body_path: build/output/release.md # created by prepare_release.sh
          files: |
            build/output/images/*.xz

      - name: Upload logs as artifact ${{ matrix.board }}
        uses: actions/upload-artifact@v2
        with:
          name: build-logs
          path: build/output/images/build.logs.*.xz

      - name: Finish build with status
        run: |
          if [[ "${{ steps.buildFirst.outcome }}" == "failure" ]]; then
            echo "buildFirst failed"
            exit 1
          fi

          if [[ "${{ steps.buildBoard.outcome }}" == "failure" ]]; then
            echo "buildBoard failed"
            exit 2
          fi
